{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import manifold\n",
    "from scipy.optimize import minimize  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x, y, component_num):\n",
    "    np.random.seed(42)\n",
    "    ones = (y == 1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    gmm_1 = GaussianMixture(n_components=component_num)\n",
    "    gmm_1.fit(x2)\n",
    "    m1 = gmm_1.means_\n",
    "    p1 = gmm_1.precisions_\n",
    "\n",
    "    zeros = (y == 0).astype(bool)\n",
    "    x2b = x[zeros]\n",
    "    gmm_0 = GaussianMixture(n_components=component_num)\n",
    "    gmm_0.fit(x2b)\n",
    "    m2 = gmm_0.means_\n",
    "    p2 = gmm_0.precisions_\n",
    "\n",
    "    ms = np.concatenate((m1, m2), axis=0)\n",
    "    ps = np.concatenate((p1, p2), axis=0)\n",
    "\n",
    "    return ms, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "oof_gmm = np.zeros(len(train))\n",
    "oof_gmm_2 = np.zeros(len(train))\n",
    "oof_gmm_3 = np.zeros(len(train))\n",
    "preds_gmm = np.zeros(len(test))\n",
    "records_gmm = []\n",
    "\n",
    "# 512 models\n",
    "for i in tqdm_notebook(range(512)):\n",
    "\n",
    "    train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "    idx1 = train2.index\n",
    "    idx2 = test2.index\n",
    "    train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "                     ('scaler', StandardScaler())])\n",
    "    data2 = pipe.fit_transform(data[cols])\n",
    "    train3 = data2[:train2.shape[0]]\n",
    "    test3 = data2[train2.shape[0]:]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=15, random_state=42,shuffle=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        #######################################################################################\n",
    "        cluster_per_class = 2\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "        \n",
    "        gmm_2 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm_2.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob_2 = gmm_2.predict_proba(train3[test_index,:])\n",
    "        prob_class_2 = np.zeros(prob_2.shape[0])\n",
    "\n",
    "        for j in range(prob_2.shape[0]):\n",
    "            if(np.argmax(prob_2,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class_2[j] = np.max(prob_2,axis=1)[j]\n",
    "            else:\n",
    "                prob_class_2[j] = 1 - np.max(prob_2,axis=1)[j]\n",
    "                \n",
    "        #######################################################################################\n",
    "        cluster_per_class = 3\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "        \n",
    "        gmm_3 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm_3.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob_3 = gmm_3.predict_proba(train3[test_index,:])\n",
    "        prob_class_3 = np.zeros(prob_3.shape[0])\n",
    "\n",
    "        for j in range(prob_3.shape[0]):\n",
    "            if(np.argmax(prob_3,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class_3[j] = np.max(prob_3,axis=1)[j]\n",
    "            else:\n",
    "                prob_class_3[j] = 1 - np.max(prob_3,axis=1)[j]\n",
    "        \n",
    "        #######################################################################################\n",
    "        oof_gmm_2[idx1[test_index]] = prob_class_2\n",
    "        oof_gmm_3[idx1[test_index]] = prob_class_3\n",
    "        \n",
    "    gmm_2_score = roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1])\n",
    "    gmm_3_score = roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1])\n",
    "    gmm_score = [gmm_2_score,gmm_3_score]\n",
    "    \n",
    "    if(np.argmax(gmm_score) == 0):\n",
    "        cluster_per_class = 2\n",
    "    else:\n",
    "        cluster_per_class = 3\n",
    "\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values, cluster_per_class)\n",
    "        gmm = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob = gmm.predict_proba(train3[test_index,:])\n",
    "        prob_class = np.zeros(prob.shape[0])\n",
    "\n",
    "        for j in range(prob.shape[0]):\n",
    "            if(np.argmax(prob,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class[j] = np.max(prob,axis=1)[j]\n",
    "            else:\n",
    "                prob_class[j] = 1 - np.max(prob,axis=1)[j]\n",
    "\n",
    "        oof_gmm[idx1[test_index]] = prob_class\n",
    "        \n",
    "        prob_test = gmm.predict_proba(test3)\n",
    "        prob_test_class = np.zeros(prob_test.shape[0])\n",
    "        for j in range(prob_test.shape[0]):\n",
    "            if(np.argmax(prob_test,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_test_class[j] = np.max(prob_test,axis=1)[j]\n",
    "            else:\n",
    "                prob_test_class[j] = 1 - np.max(prob_test,axis=1)[j]\n",
    "\n",
    "        preds_gmm[idx2] += prob_test_class / skf.n_splits\n",
    "        \n",
    "#     print(i, cluster_per_class, roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm[idx1]))\n",
    "    records_gmm.append(roc_auc_score(train['target'][idx1].values, oof_gmm[idx1]))\n",
    "        \n",
    "auc = roc_auc_score(train['target'], oof_gmm)\n",
    "print(f'AUC: {auc:.5}')\n",
    "#0.97436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr in range(1):\n",
    "    test['target'] = preds_gmm\n",
    "    test.loc[test['target'] > 0.96, 'target'] = 1\n",
    "    test.loc[test['target'] < 0.04, 'target'] = 0\n",
    "    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n",
    "    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n",
    "    print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n",
    "    \n",
    "    new_train.loc[oof_gmm > 0.98, 'target'] = 1\n",
    "    new_train.loc[oof_gmm < 0.02, 'target'] = 0\n",
    "    \n",
    "    oof_gmm2 = np.zeros(len(train))\n",
    "    oof_gmm_2 = np.zeros(len(train))\n",
    "    oof_gmm_3 = np.zeros(len(train))\n",
    "    preds_gmm = np.zeros(len(test))\n",
    "    records_gmm = []\n",
    "    \n",
    "    for i in tqdm_notebook(range(512)):\n",
    "\n",
    "        train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "        idx1 = train2.index\n",
    "        idx2 = test2.index\n",
    "        train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "                         ('scaler', StandardScaler())])\n",
    "        data2 = pipe.fit_transform(data[cols])\n",
    "        train3 = data2[:train2.shape[0]]\n",
    "        test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=2019,shuffle=True)\n",
    "\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "            \n",
    "            oof_test_index = [t for t in test_index if t < len(idx1)]\n",
    "\n",
    "            #######################################################################################\n",
    "            cluster_per_class = 2\n",
    "            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "\n",
    "            gmm_2 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "            gmm_2.fit(np.concatenate([train3,test3],axis = 0))\n",
    "            \n",
    "            if len(oof_test_index) > 0:\n",
    "                prob_2 = gmm_2.predict_proba(train3[oof_test_index,:])\n",
    "                prob_class_2 = np.zeros(prob_2.shape[0])\n",
    "\n",
    "            for j in range(prob_2.shape[0]):\n",
    "                if(np.argmax(prob_2,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                    prob_class_2[j] = np.max(prob_2,axis=1)[j]\n",
    "                else:\n",
    "                    prob_class_2[j] = 1 - np.max(prob_2,axis=1)[j]\n",
    "\n",
    "            #######################################################################################\n",
    "            cluster_per_class = 3\n",
    "            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "\n",
    "            gmm_3 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "            gmm_3.fit(np.concatenate([train3,test3],axis = 0))\n",
    "            \n",
    "            if len(oof_test_index) > 0:\n",
    "                prob_3 = gmm_3.predict_proba(train3[oof_test_index,:])\n",
    "                prob_class_3 = np.zeros(prob_3.shape[0])\n",
    "\n",
    "            for j in range(prob_3.shape[0]):\n",
    "                if(np.argmax(prob_3,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                    prob_class_3[j] = np.max(prob_3,axis=1)[j]\n",
    "                else:\n",
    "                    prob_class_3[j] = 1 - np.max(prob_3,axis=1)[j]\n",
    "\n",
    "            #######################################################################################\n",
    "            oof_gmm_2[idx1[oof_test_index]] = prob_class_2\n",
    "            oof_gmm_3[idx1[oof_test_index]] = prob_class_3\n",
    "\n",
    "        gmm_2_score = roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1])\n",
    "        gmm_3_score = roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1])\n",
    "        gmm_score = [gmm_2_score,gmm_3_score]\n",
    "\n",
    "        if(np.argmax(gmm_score) == 0):\n",
    "            cluster_per_class = 2\n",
    "        else:\n",
    "            cluster_per_class = 3\n",
    "\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "            \n",
    "            oof_test_index = [t for t in test_index if t < len(idx1)]\n",
    "\n",
    "            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values, cluster_per_class)\n",
    "            gmm = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "            gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "            \n",
    "            if len(oof_test_index) > 0:\n",
    "                prob = gmm.predict_proba(train3[oof_test_index,:])\n",
    "                prob_class = np.zeros(prob.shape[0])\n",
    "\n",
    "            for j in range(prob.shape[0]):\n",
    "                if(np.argmax(prob,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                    prob_class[j] = np.max(prob,axis=1)[j]\n",
    "                else:\n",
    "                    prob_class[j] = 1 - np.max(prob,axis=1)[j]\n",
    "\n",
    "            oof_gmm2[idx1[oof_test_index]] = prob_class\n",
    "\n",
    "            prob_test = gmm.predict_proba(test3)\n",
    "            prob_test_class = np.zeros(prob_test.shape[0])\n",
    "            for j in range(prob_test.shape[0]):\n",
    "                if(np.argmax(prob_test,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                    prob_test_class[j] = np.max(prob_test,axis=1)[j]\n",
    "                else:\n",
    "                    prob_test_class[j] = 1 - np.max(prob_test,axis=1)[j]\n",
    "\n",
    "            preds_gmm[idx2] += prob_test_class / skf.n_splits\n",
    "\n",
    "    #     print(i, cluster_per_class, roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm2[idx1]))\n",
    "        records_gmm.append(roc_auc_score(train['target'][idx1].values, oof_gmm2[idx1]))\n",
    "\n",
    "    auc = roc_auc_score(train['target'], oof_gmm2)\n",
    "    print(f'AUC: {auc:.5}')\n",
    "#     AUC: 0.97461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = preds_gmm\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
