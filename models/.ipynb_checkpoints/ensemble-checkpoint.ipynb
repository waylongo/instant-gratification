{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import manifold\n",
    "from scipy.optimize import minimize  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "import artgor_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 258) (131073, 257)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_qda = np.zeros(len(train))\n",
    "oof_mlp = np.zeros(len(train))\n",
    "oof_gmm = np.zeros(len(train))\n",
    "oof_svc = np.zeros(len(train))\n",
    "oof_nusvc = np.zeros(len(train))\n",
    "oof_knn = np.zeros(len(train))\n",
    "oof_lr = np.zeros(len(train))\n",
    "\n",
    "preds_qda = np.zeros(len(test))\n",
    "preds_mlp = np.zeros(len(test))\n",
    "preds_gmm = np.zeros(len(test))\n",
    "preds_svc = np.zeros(len(test))\n",
    "preds_nusvc = np.zeros(len(test))\n",
    "preds_knn = np.zeros(len(test))\n",
    "preds_lr = np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f553c57dc5450c8f27d83b089e9b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 512 models\n",
    "for i in tqdm_notebook(range(512)):\n",
    "\n",
    "    train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "    idx1 = train2.index\n",
    "    idx2 = test2.index\n",
    "    train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "                     ('scaler', StandardScaler())])\n",
    "    data2 = pipe.fit_transform(data[cols])\n",
    "    train3 = data2[:train2.shape[0]]\n",
    "    test3 = data2[train2.shape[0]:]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=11, random_state=2019,shuffle=True)\n",
    "    ###################################################################################################\n",
    "    #QDA:0.96491\n",
    "\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "        qda = QuadraticDiscriminantAnalysis(0.1)\n",
    "        qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_qda[idx1[test_index]] = qda.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_qda[idx2] += qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "    ###################################################################################################\n",
    "    #MLP:0.914\n",
    "\n",
    "        mlp = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(256, ))\n",
    "        mlp.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_mlp[idx1[test_index]] = mlp.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_mlp[idx2] += mlp.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "    ###################################################################################################\n",
    "    #GMM: 0.5 plain, 0.9675 with lasso init\n",
    "\n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        oof_gmm[idx1[test_index]] = gmm.predict_proba(train3[test_index,:])[:,0]\n",
    "        preds_gmm[idx2] += gmm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "    \n",
    "    ###################################################################################################\n",
    "    #SVC: 0.94262 ,0.87(3), 0.84(5)\n",
    "\n",
    "        # MODEL WITH SUPPORT VECTOR MACHINE\n",
    "        svc = SVC(probability=True,kernel='poly',degree=4,gamma='auto')\n",
    "        svc.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_svc[idx1[test_index]] = svc.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_svc[idx2] += svc.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    \n",
    "    ###################################################################################################\n",
    "    #NuSVC: 0.95677, 0.93285(3), 0.93268(5)\n",
    "        \n",
    "        nusvc = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "        nusvc.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_nusvc[idx1[test_index]] = nusvc.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_nusvc[idx2] += nusvc.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    \n",
    "    ###################################################################################################\n",
    "    #kNN: 0.91823 (16), 0.91892* (10), 0.91385(6), 0.91721(8)\n",
    "\n",
    "        knn = neighbors.KNeighborsClassifier(n_neighbors=10, p=2)\n",
    "        knn.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_knn[idx1[test_index]] = knn.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_knn[idx2] += knn.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "    ###################################################################################################\n",
    "    #LR:0.79655\n",
    "\n",
    "        lr = linear_model.LogisticRegression(solver='saga',penalty='l1',C=0.1)\n",
    "        lr.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lr[idx1[test_index]] = lr.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_lr[idx2] += lr.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qda 0.9649133103878258\n",
      "mlp 0.9136423018870907\n",
      "gmm 0.967510657292127\n",
      "svc 0.9426005464450284\n",
      "nusvc 0.9567668612583915\n",
      "knn 0.9189180115210822\n",
      "lr 0.796545408129143\n"
     ]
    }
   ],
   "source": [
    "print('qda', roc_auc_score(train['target'], oof_qda))\n",
    "print('mlp', roc_auc_score(train['target'], oof_mlp))\n",
    "print('gmm', roc_auc_score(train['target'], oof_gmm))\n",
    "print('svc', roc_auc_score(train['target'], oof_svc))\n",
    "print('nusvc', roc_auc_score(train['target'], oof_nusvc))\n",
    "print('knn', roc_auc_score(train['target'], oof_knn))\n",
    "print('lr', roc_auc_score(train['target'], oof_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_qda = oof_qda.reshape(-1, 1)\n",
    "preds_qda = preds_qda.reshape(-1, 1)\n",
    "\n",
    "oof_mlp = oof_mlp.reshape(-1, 1)\n",
    "preds_mlp = preds_mlp.reshape(-1, 1)\n",
    "\n",
    "oof_gmm = oof_gmm.reshape(-1, 1)\n",
    "preds_gmm = preds_gmm.reshape(-1, 1)\n",
    "\n",
    "oof_svc = oof_svc.reshape(-1, 1)\n",
    "preds_svc = preds_svc.reshape(-1, 1)\n",
    "\n",
    "oof_nusvc = oof_nusvc.reshape(-1, 1)\n",
    "preds_nusvc = preds_nusvc.reshape(-1, 1)\n",
    "\n",
    "oof_knn = oof_knn.reshape(-1, 1)\n",
    "preds_knn = preds_knn.reshape(-1, 1)\n",
    "\n",
    "oof_lr = oof_lr.reshape(-1, 1)\n",
    "preds_lr = preds_lr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 6) (131073, 6)\n"
     ]
    }
   ],
   "source": [
    "tr = np.concatenate((oof_qda, oof_mlp, oof_gmm, oof_svc, oof_nusvc, oof_knn), axis=1)\n",
    "te = np.concatenate((preds_qda, preds_mlp, preds_gmm, preds_svc, preds_nusvc, preds_knn), axis=1)\n",
    "print(tr.shape, te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack CV score = 0.96792\n"
     ]
    }
   ],
   "source": [
    "# logistic regression stacking\n",
    "oof_stack_lr = np.zeros(len(train)) \n",
    "preds_stack_lr = np.zeros(len(test))\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(tr, train['target']):\n",
    "    stack_lr = linear_model.LogisticRegression() # solver='liblinear',penalty='l1',C=0.1\n",
    "    stack_lr.fit(tr[train_index], train['target'][train_index])\n",
    "    oof_stack_lr[test_index] = stack_lr.predict_proba(tr[test_index,:])[:,1]\n",
    "    preds_stack_lr += stack_lr.predict_proba(te)[:,1] / skf.n_splits\n",
    "    \n",
    "print('stack CV score =',round(roc_auc_score(train['target'],oof_stack_lr),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:0.49617\tvalid_data-mae:0.496184\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 300 rounds.\n",
      "[1000]\ttrain-mae:0.112487\tvalid_data-mae:0.113231\n",
      "[2000]\ttrain-mae:0.108425\tvalid_data-mae:0.109318\n",
      "[3000]\ttrain-mae:0.105462\tvalid_data-mae:0.106444\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mae:0.104242\tvalid_data-mae:0.105273\n",
      "\n",
      "[0]\ttrain-mae:0.49618\tvalid_data-mae:0.496172\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 300 rounds.\n",
      "[1000]\ttrain-mae:0.11314\tvalid_data-mae:0.112765\n",
      "[2000]\ttrain-mae:0.109043\tvalid_data-mae:0.10869\n",
      "[3000]\ttrain-mae:0.106125\tvalid_data-mae:0.105783\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mae:0.104881\tvalid_data-mae:0.104536\n",
      "\n",
      "[0]\ttrain-mae:0.496182\tvalid_data-mae:0.496171\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 300 rounds.\n",
      "[1000]\ttrain-mae:0.112994\tvalid_data-mae:0.112079\n",
      "[2000]\ttrain-mae:0.108929\tvalid_data-mae:0.108125\n",
      "[3000]\ttrain-mae:0.106009\tvalid_data-mae:0.105278\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mae:0.10477\tvalid_data-mae:0.104082\n",
      "\n",
      "[0]\ttrain-mae:0.496173\tvalid_data-mae:0.49618\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 300 rounds.\n",
      "[1000]\ttrain-mae:0.112166\tvalid_data-mae:0.114181\n",
      "[2000]\ttrain-mae:0.10814\tvalid_data-mae:0.110148\n",
      "[3000]\ttrain-mae:0.105273\tvalid_data-mae:0.107267\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mae:0.104044\tvalid_data-mae:0.106022\n",
      "\n",
      "[0]\ttrain-mae:0.496175\tvalid_data-mae:0.496178\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 300 rounds.\n",
      "[1000]\ttrain-mae:0.112738\tvalid_data-mae:0.112621\n",
      "[2000]\ttrain-mae:0.108621\tvalid_data-mae:0.108768\n",
      "[3000]\ttrain-mae:0.10569\tvalid_data-mae:0.105989\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mae:0.104436\tvalid_data-mae:0.104813\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9676620151691299"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_params = {\n",
    "#     'eta': 0.01,\n",
    "#     'max_depth': 5,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree': 0.3,\n",
    "#     'objective': 'gpu:reg:linear',\n",
    "#     'eval_metric': 'mae',\n",
    "#     'silent': True,\n",
    "#     'tree_method': 'gpu_hist'\n",
    "# }\n",
    "\n",
    "# oof_xgb = np.zeros(len(train)) \n",
    "# preds_xgb = np.zeros(len(test))\n",
    "\n",
    "# for train_index, test_index in skf.split(tr, train['target']):\n",
    "#         train_data = xgb.DMatrix(data=tr[train_index], label=train['target'][train_index])\n",
    "#         valid_data = xgb.DMatrix(data=tr[test_index], label=train['target'][test_index])\n",
    "\n",
    "#         watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "#         model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=300, verbose_eval=1000, params=xgb_params)\n",
    "#         oof_xgb[test_index] = model.predict(xgb.DMatrix(tr[test_index,:]), ntree_limit=model.best_ntree_limit)\n",
    "#         preds_xgb += model.predict(xgb.DMatrix(te), ntree_limit=model.best_ntree_limit) / skf.n_splits\n",
    "\n",
    "# roc_auc_score(train['target'],oof_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99004 Test Records added for iteration :  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f07dedb254479eba37b9da6f7deaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 6) (131073, 6)\n",
      "stack CV score = 0.97213\n",
      "106899 Test Records added for iteration :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0da50d48324602a03cdd68373aad30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 6) (131073, 6)\n",
      "stack CV score = 0.97181\n",
      "108566 Test Records added for iteration :  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098a9674b0134956ba5c5ac912403dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 6) (131073, 6)\n",
      "stack CV score = 0.97162\n",
      "108907 Test Records added for iteration :  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e71c735a7145878f9be3671e972514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 6) (131073, 6)\n",
      "stack CV score = 0.97167\n"
     ]
    }
   ],
   "source": [
    "for itr in range(4):\n",
    "    test['target'] = preds_stack_lr\n",
    "    test.loc[test['target'] > 0.94, 'target'] = 1\n",
    "    test.loc[test['target'] < 0.06, 'target'] = 0\n",
    "    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n",
    "    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n",
    "    print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n",
    "    new_train.loc[oof_stack_lr > 0.98, 'target'] = 1\n",
    "    new_train.loc[oof_stack_lr < 0.02, 'target'] = 0\n",
    "    oof_qda2 = np.zeros(len(train))\n",
    "    oof_mlp2 = np.zeros(len(train))\n",
    "    oof_gmm2 = np.zeros(len(train))\n",
    "    oof_svc2 = np.zeros(len(train))\n",
    "    oof_nusvc2 = np.zeros(len(train))\n",
    "    oof_knn2 = np.zeros(len(train))\n",
    "    oof_lr2 = np.zeros(len(train))\n",
    "\n",
    "    preds_qda = np.zeros(len(test))\n",
    "    preds_mlp = np.zeros(len(test))\n",
    "    preds_gmm = np.zeros(len(test))\n",
    "    preds_svc = np.zeros(len(test))\n",
    "    preds_nusvc = np.zeros(len(test))\n",
    "    preds_knn = np.zeros(len(test))\n",
    "    preds_lr = np.zeros(len(test))\n",
    "\n",
    "    for i in tqdm_notebook(range(512)):\n",
    "\n",
    "        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n",
    "        idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n",
    "        data2 = pipe.fit_transform(data[cols])\n",
    "        train3 = data2[:train2.shape[0]]\n",
    "        test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=42)    \n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "            oof_test_index = [t for t in test_index if t < len(idx1)]\n",
    "        ###################################################################################################\n",
    "        #QDA\n",
    "        \n",
    "            qda = QuadraticDiscriminantAnalysis(0.1)\n",
    "            qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_qda2[idx1[oof_test_index]] = qda.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_qda[idx2] += qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #MLP\n",
    "\n",
    "            mlp = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(256, ))\n",
    "            mlp.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_mlp2[idx1[oof_test_index]] = mlp.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_mlp[idx2] += mlp.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #GMM\n",
    "\n",
    "            # MODEL AND PREDICT WITH QDA\n",
    "            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "\n",
    "            gmm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "            gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_gmm2[idx1[oof_test_index]] = gmm.predict_proba(train3[oof_test_index,:])[:,0]\n",
    "            preds_gmm[idx2] += gmm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #SVC\n",
    "\n",
    "            # MODEL WITH SUPPORT VECTOR MACHINE\n",
    "            svc = SVC(probability=True,kernel='poly',degree=4,gamma='auto')\n",
    "            svc.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_svc2[idx1[oof_test_index]] = svc.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_svc[idx2] += svc.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #NuSVC\n",
    "\n",
    "            nusvc = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "            nusvc.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_nusvc2[idx1[oof_test_index]] = nusvc.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_nusvc[idx2] += nusvc.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #kNN\n",
    "\n",
    "            knn = neighbors.KNeighborsClassifier(n_neighbors=10, p=2)\n",
    "            knn.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_knn2[idx1[oof_test_index]] = knn.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_knn[idx2] += knn.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "        ###################################################################################################\n",
    "        #LR\n",
    "\n",
    "            lr = linear_model.LogisticRegression(solver='saga',penalty='l1',C=0.1)\n",
    "            lr.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof_lr2[idx1[oof_test_index]] = lr.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds_lr[idx2] += lr.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    \n",
    "    print('qda', roc_auc_score(train['target'], oof_qda2))\n",
    "    print('mlp', roc_auc_score(train['target'], oof_mlp2))\n",
    "    print('gmm', roc_auc_score(train['target'], oof_gmm2))\n",
    "    print('svc', roc_auc_score(train['target'], oof_svc2))\n",
    "    print('nusvc', roc_auc_score(train['target'], oof_nusvc2))\n",
    "    print('knn', roc_auc_score(train['target'], oof_knn2))\n",
    "    print('lr', roc_auc_score(train['target'], oof_lr2))\n",
    "    \n",
    "    oof_qda2 = oof_qda2.reshape(-1, 1)\n",
    "    preds_qda = preds_qda.reshape(-1, 1)\n",
    "\n",
    "    oof_mlp2 = oof_mlp2.reshape(-1, 1)\n",
    "    preds_mlp = preds_mlp.reshape(-1, 1)\n",
    "\n",
    "    oof_gmm2 = oof_gmm2.reshape(-1, 1)\n",
    "    preds_gmm = preds_gmm.reshape(-1, 1)\n",
    "\n",
    "    oof_svc2 = oof_svc2.reshape(-1, 1)\n",
    "    preds_svc = preds_svc.reshape(-1, 1)\n",
    "\n",
    "    oof_nusvc2 = oof_nusvc2.reshape(-1, 1)\n",
    "    preds_nusvc = preds_nusvc.reshape(-1, 1)\n",
    "\n",
    "    oof_knn2 = oof_knn2.reshape(-1, 1)\n",
    "    preds_knn = preds_knn.reshape(-1, 1)\n",
    "\n",
    "    oof_lr2 = oof_lr2.reshape(-1, 1)\n",
    "    preds_lr = preds_lr.reshape(-1, 1)\n",
    "    \n",
    "    tr = np.concatenate((oof_qda2, oof_mlp2, oof_gmm2, oof_svc2, oof_nusvc2, oof_knn2), axis=1)\n",
    "    te = np.concatenate((preds_qda, preds_mlp, preds_gmm, preds_svc, preds_nusvc, preds_knn), axis=1)\n",
    "    print(tr.shape, te.shape)\n",
    "    \n",
    "    # logistic regression stacking\n",
    "    oof_stack_lr = np.zeros(len(train)) \n",
    "    preds_stack_lr = np.zeros(len(test))\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "    for train_index, test_index in skf.split(tr, train['target']):\n",
    "        stack_lr = linear_model.LogisticRegression() # solver='liblinear',penalty='l1',C=0.1\n",
    "        stack_lr.fit(tr[train_index], train['target'][train_index])\n",
    "        oof_stack_lr[test_index] = stack_lr.predict_proba(tr[test_index,:])[:,1]\n",
    "        preds_stack_lr += stack_lr.predict_proba(te)[:,1] / skf.n_splits\n",
    "\n",
    "    print('stack CV score =',round(roc_auc_score(train['target'],oof_stack_lr),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('../input/sample_submission.csv')\n",
    "# sub['target'] = preds_stack_lr\n",
    "# sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qda 0.9702269598410957\n",
      "mlp 0.9380418544940008\n",
      "gmm 0.9682577309143473\n",
      "svc 0.9570872074179684\n",
      "nusvc 0.9661207094070379\n",
      "knn 0.9414608389619493\n",
      "lr 0.8144006353062934\n"
     ]
    }
   ],
   "source": [
    "    print('qda', roc_auc_score(train['target'], oof_qda2))\n",
    "    print('mlp', roc_auc_score(train['target'], oof_mlp2))\n",
    "    print('gmm', roc_auc_score(train['target'], oof_gmm2))\n",
    "    print('svc', roc_auc_score(train['target'], oof_svc2))\n",
    "    print('nusvc', roc_auc_score(train['target'], oof_nusvc2))\n",
    "    print('knn', roc_auc_score(train['target'], oof_knn2))\n",
    "    print('lr', roc_auc_score(train['target'], oof_lr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
