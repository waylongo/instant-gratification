{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import manifold\n",
    "from scipy.optimize import minimize  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 258) (131073, 257)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x, y, component_num):\n",
    "    np.random.seed(42)\n",
    "    ones = (y == 1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    gmm_1 = GaussianMixture(n_components=component_num)\n",
    "    gmm_1.fit(x2)\n",
    "    m1 = gmm_1.means_\n",
    "    p1 = gmm_1.precisions_\n",
    "\n",
    "    zeros = (y == 0).astype(bool)\n",
    "    x2b = x[zeros]\n",
    "    gmm_0 = GaussianMixture(n_components=component_num)\n",
    "    gmm_0.fit(x2b)\n",
    "    m2 = gmm_0.means_\n",
    "    p2 = gmm_0.precisions_\n",
    "\n",
    "    ms = np.concatenate((m1, m2), axis=0)\n",
    "    ps = np.concatenate((p1, p2), axis=0)\n",
    "\n",
    "    return ms, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bd8fc291ac45dba77ab6e561d84096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 0.9682558612658371 0.9614159639695256 0.9682558612658371\n",
      "1 2 0.973631128356738 0.9679647080561714 0.973631128356738\n",
      "2 2 0.9741083676268861 0.9617381932196748 0.9741083676268861\n",
      "3 2 0.9854189456776106 0.9852389326612847 0.9854189456776106\n",
      "4 2 0.9801217038539554 0.9771542333408458 0.9801217038539554\n",
      "5 2 0.969546700462731 0.9692667039995284 0.969546700462731\n",
      "6 2 0.9893877246625399 0.9839361622790663 0.9893877246625399\n",
      "7 3 0.9593019622547181 0.9599268841394826 0.9599268841394826\n",
      "8 2 0.9733494896085776 0.9715576118087685 0.9733494896085776\n",
      "9 2 0.9742022497704317 0.9722724403122132 0.9742022497704317\n",
      "10 2 0.9704639308297844 0.965310040005162 0.9704639308297844\n",
      "11 2 0.9813275862068966 0.9756120689655173 0.9813275862068966\n",
      "12 2 0.975355719977234 0.9748922676640378 0.975355719977234\n",
      "13 3 0.9789446808510638 0.9832680851063829 0.9832680851063829\n",
      "14 2 0.9910665714674284 0.9775091799265607 0.9910665714674284\n",
      "15 3 0.9690331304935766 0.9763503868980543 0.9763503868980543\n",
      "16 3 0.975294311475901 0.9768070574843484 0.9768070574843484\n",
      "17 2 0.9846561819798277 0.9843496121892148 0.9846561819798277\n",
      "18 2 0.979469013349243 0.9739205011559401 0.979469013349243\n",
      "19 2 0.9871683655027832 0.9862864165401575 0.9871683655027832\n",
      "20 3 0.9681750106974755 0.9697414267375755 0.9697414267375755\n",
      "21 3 0.9752827254735652 0.9763005371783997 0.9763005371783997\n",
      "22 3 0.9813662871424604 0.981893918356012 0.981893918356012\n",
      "23 2 0.9723845747180453 0.9630007636278195 0.9723845747180453\n",
      "24 2 0.9651819939062347 0.9289388330111719 0.9651819939062347\n",
      "25 2 0.9725271983231858 0.9488555078683834 0.9725271983231858\n",
      "26 2 0.9741826890868894 0.9389529041334493 0.9741826890868894\n",
      "27 2 0.9568853857332407 0.9501089909648068 0.9568853857332407\n",
      "28 3 0.9590176441214004 0.9653220884425455 0.9653220884425455\n",
      "29 3 0.9784516129032258 0.9791854838709677 0.9791854838709677\n",
      "30 2 0.9760933297065313 0.9643742255266419 0.9760933297065313\n",
      "31 3 0.9659501528768646 0.9668380740603479 0.9668380740603479\n",
      "32 2 0.9815158068170116 0.9776542065698692 0.9815158068170116\n",
      "33 3 0.9689365671641792 0.980654420206659 0.980654420206659\n",
      "34 3 0.9849895496864906 0.9857641883102646 0.9857641883102646\n",
      "35 2 0.9792503346720214 0.9703620684287537 0.9792503346720214\n",
      "36 3 0.9656754772393539 0.9687792017087172 0.9687792017087172\n",
      "37 3 0.9676119008458647 0.9788900963345865 0.9788900963345865\n",
      "38 2 0.9820360579006674 0.9741772846782815 0.9820360579006674\n",
      "39 2 0.978588773699449 0.9735686933781639 0.978588773699449\n",
      "40 2 0.9773729062591829 0.9733078656087766 0.9773729062591829\n",
      "41 3 0.9693102023957042 0.9704460966542751 0.9704460966542751\n",
      "42 2 0.9635039128710015 0.9341573803599121 0.9635039128710015\n",
      "43 3 0.9702224985566461 0.9776317152965908 0.9776317152965908\n",
      "44 2 0.9752429356859736 0.965413629970592 0.9752429356859736\n",
      "45 2 0.9663411024787274 0.9539474657787643 0.9663411024787274\n",
      "46 2 0.976695627130034 0.9694235107761725 0.976695627130034\n",
      "47 2 0.9709909749699908 0.9681530550245261 0.9709909749699908\n",
      "48 2 0.9711938554491565 0.96827975376197 0.9711938554491565\n",
      "49 2 0.9620344932844932 0.9564178876678877 0.9620344932844932\n",
      "50 3 0.9720282024248814 0.9746112282551398 0.9746112282551398\n",
      "51 2 0.9714123904264749 0.9695348665419088 0.9714123904264749\n",
      "52 2 0.9737228373592011 0.9641181913909187 0.9737228373592011\n",
      "53 2 0.9760748157694722 0.9758434949274644 0.9760748157694722\n",
      "54 3 0.9702018086773078 0.9711170055997641 0.9711170055997641\n",
      "55 2 0.983501708512851 0.9762368147377805 0.983501708512851\n",
      "56 2 0.9811011235955055 0.9739176029962546 0.9811011235955055\n",
      "57 3 0.9791119364676752 0.9797536008696439 0.9797536008696439\n",
      "58 3 0.9816788755321814 0.9821249686952167 0.9821249686952167\n",
      "59 3 0.9686795964345185 0.9697081006954646 0.9697081006954646\n",
      "60 2 0.9774822091698598 0.9738796585344203 0.9774822091698598\n",
      "61 3 0.9646860834396459 0.9722930973643495 0.9722930973643495\n",
      "62 2 0.9704587479087786 0.9679052566698952 0.9704587479087786\n",
      "63 2 0.9787722066386162 0.9478290088826555 0.9787722066386162\n",
      "64 2 0.9792475694731333 0.9709851551956815 0.9792475694731333\n",
      "65 2 0.9798944476576055 0.9721153846153845 0.9798944476576055\n",
      "66 2 0.9792741999523544 0.9069880092114667 0.9792741999523544\n",
      "67 2 0.9770180566974209 0.9734934989799338 0.9770180566974209\n",
      "68 2 0.9684998063016529 0.9580400955578512 0.9684998063016529\n",
      "69 3 0.9711636394500085 0.9719558082951395 0.9719558082951395\n",
      "70 3 0.9739029677805189 0.987052403378934 0.987052403378934\n",
      "71 3 0.9563669996300407 0.971668516463189 0.971668516463189\n",
      "72 2 0.9670633548960544 0.9589485292907345 0.9670633548960544\n",
      "73 3 0.9723580100115969 0.9725488469047724 0.9725488469047724\n",
      "74 2 0.9736706157872986 0.9722757955641274 0.9736706157872986\n",
      "75 3 0.9647201201017187 0.9725788167529643 0.9725788167529643\n",
      "76 2 0.9751702069716774 0.9747004357298474 0.9751702069716774\n",
      "77 2 0.980367231638418 0.9676239799121155 0.980367231638418\n",
      "78 2 0.9629654493376296 0.9571398734932568 0.9629654493376296\n",
      "79 3 0.967721335268505 0.9698766328011612 0.9698766328011612\n",
      "80 2 0.986371738778156 0.9844919786096257 0.986371738778156\n",
      "81 2 0.9589416058394162 0.9586302282470166 0.9589416058394162\n",
      "82 3 0.964369982227125 0.9719540969540971 0.9719540969540971\n",
      "83 2 0.9837262245722259 0.96925901446721 0.9837262245722259\n",
      "84 3 0.9723270440251572 0.9799465047350538 0.9799465047350538\n",
      "85 2 0.9605822873082287 0.9255753138075314 0.9605822873082287\n",
      "86 3 0.9873074229691876 0.9900816095669037 0.9900816095669037\n",
      "87 2 0.9539148962261257 0.929075078941721 0.9539148962261257\n",
      "88 2 0.9761312217194571 0.95340174531351 0.9761312217194571\n",
      "89 2 0.9542779874587655 0.9510238045707153 0.9542779874587655\n",
      "90 3 0.9758648179700813 0.9817579291263502 0.9817579291263502\n",
      "91 2 0.9710910518053374 0.9641051805337519 0.9710910518053374\n",
      "92 3 0.9698905109489049 0.9782466545012166 0.9782466545012166\n",
      "93 2 0.9546726001271455 0.9370311506675143 0.9546726001271455\n",
      "94 3 0.9602207612039328 0.9625580553712528 0.9625580553712528\n",
      "95 2 0.9606340263944223 0.955023655378486 0.9606340263944223\n",
      "96 2 0.9653008519282554 0.9529707257924823 0.9653008519282554\n",
      "97 2 0.974576549369748 0.9666655724789917 0.974576549369748\n",
      "98 2 0.9716943419434194 0.965559655596556 0.9716943419434194\n",
      "99 2 0.9593466857415356 0.9467334287076776 0.9593466857415356\n",
      "100 3 0.9707234471825912 0.9729355814958929 0.9729355814958929\n",
      "101 2 0.9833363277039168 0.9786950532997963 0.9833363277039168\n",
      "102 2 0.965009290894923 0.9429958640532281 0.965009290894923\n",
      "103 2 0.9614425709756449 0.9508430609597924 0.9614425709756449\n",
      "104 3 0.9609464273711098 0.9678765880217786 0.9678765880217786\n",
      "105 2 0.9720555138784697 0.9576456614153537 0.9720555138784697\n",
      "106 2 0.9796206846416051 0.9780455889242501 0.9796206846416051\n",
      "107 2 0.9636434404092397 0.9557398404982047 0.9636434404092397\n",
      "108 2 0.9665679145345184 0.9309453272286562 0.9665679145345184\n",
      "109 3 0.9694011828843291 0.9721993261319103 0.9721993261319103\n",
      "110 2 0.9813957971852708 0.9748971788445473 0.9813957971852708\n",
      "111 3 0.9783655558563307 0.9824117739246889 0.9824117739246889\n",
      "112 2 0.9758428379118034 0.9739345256586633 0.9758428379118034\n",
      "113 2 0.9797521467603436 0.9715391621129326 0.9797521467603436\n",
      "114 3 0.9635690172543137 0.9676012753188298 0.9676012753188298\n",
      "115 2 0.9754616875828996 0.9709383396252083 0.9754616875828996\n",
      "116 2 0.9714294572682034 0.9496643775094176 0.9714294572682034\n",
      "117 2 0.9765804737370792 0.9578027283626582 0.9765804737370792\n",
      "118 2 0.9803885630498533 0.9615019328179152 0.9803885630498533\n",
      "119 3 0.972540322580645 0.9732741935483872 0.9732741935483872\n",
      "120 3 0.9681289090883187 0.9783655558563308 0.9783655558563308\n",
      "121 2 0.9679877812407933 0.9646849948054768 0.9679877812407933\n",
      "122 2 0.9716598267213863 0.9663854689162488 0.9716598267213863\n",
      "123 2 0.9785589782350492 0.9743247620663593 0.9785589782350492\n",
      "124 3 0.9830701152056154 0.9831387808041505 0.9831387808041505\n",
      "125 2 0.9514694632156064 0.9131630116027031 0.9514694632156064\n",
      "126 2 0.9748431060952946 0.9728566811215558 0.9748431060952946\n",
      "127 3 0.9856513794446274 0.9865350627564927 0.9865350627564927\n",
      "128 2 0.9732728592162554 0.9500217706821481 0.9732728592162554\n",
      "129 2 0.9543886224017504 0.9511402844399562 0.9543886224017504\n",
      "130 2 0.9687698238422875 0.9647928560972039 0.9687698238422875\n",
      "131 3 0.9652996599382273 0.9677097307584314 0.9677097307584314\n",
      "132 3 0.9737369687249399 0.9791573851317237 0.9791573851317237\n",
      "133 3 0.9752376002376003 0.9810662310662313 0.9810662310662313\n",
      "134 2 0.9784525583705912 0.9725844510680577 0.9784525583705912\n",
      "135 3 0.9801220450367047 0.9848812799082055 0.9848812799082055\n",
      "136 2 0.9736495388669302 0.9707000838423765 0.9736495388669302\n",
      "137 2 0.9836049177553124 0.9732262382864791 0.9836049177553124\n",
      "138 3 0.9822829174901186 0.9851778656126482 0.9851778656126482\n",
      "139 2 0.976716965613236 0.9726835595204202 0.976716965613236\n",
      "140 3 0.9772741317513287 0.9799005067358793 0.9799005067358793\n",
      "141 2 0.9678977272727273 0.9678030303030303 0.9678977272727273\n",
      "142 2 0.9769083969465648 0.9755871990604815 0.9769083969465648\n",
      "143 2 0.9648552052785924 0.9628772605083089 0.9648552052785924\n",
      "144 3 0.967500290630086 0.9734364101371774 0.9734364101371774\n",
      "145 2 0.972185053380783 0.9646263345195729 0.972185053380783\n",
      "146 2 0.9811887602234999 0.977803870758766 0.9811887602234999\n",
      "147 2 0.9772195569770197 0.9769456289978677 0.9772195569770197\n",
      "148 2 0.9847135858300359 0.9801205954399849 0.9847135858300359\n",
      "149 2 0.9580662304447471 0.9485169561895905 0.9580662304447471\n",
      "150 2 0.96332558911384 0.9499322380794335 0.96332558911384\n",
      "151 3 0.9638057809330629 0.9702501690331307 0.9702501690331307\n",
      "152 3 0.9689271800069685 0.9703050267650692 0.9703050267650692\n",
      "153 2 0.9661875645199716 0.935980306519495 0.9661875645199716\n",
      "154 2 0.9824278721916516 0.9791901012373454 0.9824278721916516\n",
      "155 3 0.9789049204587497 0.9801257861635221 0.9801257861635221\n",
      "156 2 0.9836718348596125 0.9760479946806903 0.9836718348596125\n",
      "157 2 0.9859245867768596 0.9666236225895316 0.9859245867768596\n",
      "158 2 0.9725561143137496 0.9696737397277075 0.9725561143137496\n",
      "159 3 0.9752455948853893 0.9825588648058631 0.9825588648058631\n",
      "160 2 0.9785785161001217 0.9773622047244095 0.9785785161001217\n",
      "161 2 0.9727978883861237 0.9630542986425339 0.9727978883861237\n",
      "162 2 0.9594285714285713 0.9587836734693878 0.9594285714285713\n",
      "163 3 0.9818381764862705 0.9836210343908292 0.9836210343908292\n",
      "164 3 0.9850943396226417 0.9873886792452831 0.9873886792452831\n",
      "165 2 0.9763717890256878 0.9687946496428028 0.9763717890256878\n",
      "166 2 0.9545022388517451 0.9165797705943691 0.9545022388517451\n",
      "167 3 0.9746929958099546 0.9769764980499616 0.9769764980499616\n",
      "168 2 0.9750194623803635 0.9744012455923434 0.9750194623803635\n",
      "169 3 0.9563169506778529 0.9895419049554388 0.9895419049554388\n",
      "170 2 0.9770687689027717 0.9605500190060654 0.9770687689027717\n",
      "171 2 0.9707987671390714 0.9624956792257172 0.9707987671390714\n",
      "172 2 0.9768612731575694 0.9767934397564029 0.9768612731575694\n",
      "173 3 0.9744343891402716 0.980818721719457 0.980818721719457\n",
      "174 2 0.9782382766982647 0.9781123043491953 0.9782382766982647\n",
      "175 3 0.950392593279545 0.9617144270302018 0.9617144270302018\n",
      "176 2 0.9798787291519848 0.9588838971106413 0.9798787291519848\n",
      "177 3 0.9700005620503598 0.9716726618705035 0.9716726618705035\n",
      "178 2 0.9732473199886159 0.9670809221136514 0.9732473199886159\n",
      "179 2 0.9742755664839573 0.9568840394105493 0.9742755664839573\n",
      "180 3 0.9776083467094703 0.9782102728731942 0.9782102728731942\n",
      "181 3 0.9702256809338521 0.9747859922178989 0.9747859922178989\n",
      "182 3 0.9737705400356004 0.9775438751342366 0.9775438751342366\n",
      "183 3 0.9847664327008285 0.9854064394525481 0.9854064394525481\n",
      "184 2 0.9760757575757577 0.9619772727272728 0.9760757575757577\n",
      "185 2 0.9858099391854538 0.9779265720662613 0.9858099391854538\n",
      "186 2 0.9790767045454546 0.9754048295454545 0.9790767045454546\n",
      "187 2 0.9684911242603551 0.9586110246029274 0.9684911242603551\n",
      "188 2 0.9748648320272157 0.9612417228600936 0.9748648320272157\n",
      "189 2 0.9800541173491992 0.9741993164124311 0.9800541173491992\n",
      "190 2 0.9733690608065628 0.9598814406754289 0.9733690608065628\n",
      "191 2 0.9799853495505669 0.9655409220626612 0.9799853495505669\n",
      "192 2 0.9791269403514301 0.9652194468521 0.9791269403514301\n",
      "193 3 0.9657585905210125 0.9701782966784325 0.9701782966784325\n",
      "194 2 0.9694787713664818 0.9619619863124776 0.9694787713664818\n",
      "195 3 0.9495499999999999 0.9589333333333334 0.9589333333333334\n",
      "196 2 0.9823579971737832 0.9796046210101539 0.9823579971737832\n",
      "197 2 0.9662783223525631 0.960501365900691 0.9662783223525631\n",
      "198 2 0.960473458861649 0.9551338215602321 0.960473458861649\n",
      "199 2 0.9743005197472845 0.957190874856058 0.9743005197472845\n",
      "200 2 0.9812644742936545 0.9769260460089548 0.9812644742936545\n",
      "201 2 0.9810807855145369 0.9776750144510928 0.9810807855145369\n",
      "202 2 0.978155737704918 0.9596885245901638 0.978155737704918\n",
      "203 2 0.9804762353532498 0.9601592686834418 0.9804762353532498\n",
      "204 2 0.984565713835735 0.9816757224978343 0.984565713835735\n",
      "205 3 0.9647350923704919 0.9687609589137174 0.9687609589137174\n",
      "206 3 0.9604706175298805 0.9605717753984064 0.9605717753984064\n",
      "207 2 0.9572576552190831 0.9272119776687532 0.9572576552190831\n",
      "208 2 0.966704822954823 0.9552274114774115 0.966704822954823\n",
      "209 2 0.9768592297476759 0.9705179282868526 0.9768592297476759\n",
      "210 2 0.9826053639846744 0.9740383141762452 0.9826053639846744\n",
      "211 3 0.9497911646586347 0.9613493975903614 0.9613493975903614\n",
      "212 2 0.9810168997668999 0.9779137529137529 0.9810168997668999\n",
      "213 2 0.9682964808470882 0.9588212394892558 0.9682964808470882\n",
      "214 2 0.9816161709750146 0.980311312887983 0.9816161709750146\n",
      "215 2 0.979335162290234 0.9706149570670182 0.979335162290234\n",
      "216 2 0.9786194920772737 0.9729681540512884 0.9786194920772737\n",
      "217 2 0.975806691449814 0.9562081784386616 0.975806691449814\n",
      "218 3 0.9811571598336304 0.9833481877599525 0.9833481877599525\n",
      "219 2 0.9734676547784469 0.9685348155010036 0.9734676547784469\n",
      "220 3 0.9680873621713317 0.9707530594935176 0.9707530594935176\n",
      "221 2 0.959718117754035 0.8994771538986133 0.959718117754035\n",
      "222 2 0.9488916666666666 0.9380333333333334 0.9488916666666666\n",
      "223 2 0.98216882601798 0.9810368191433104 0.98216882601798\n",
      "224 2 0.9734468476760239 0.9733087896916707 0.9734468476760239\n",
      "225 3 0.9719253604749788 0.974286118179248 0.974286118179248\n",
      "226 2 0.9727139827785631 0.9647699524482716 0.9727139827785631\n",
      "227 3 0.980184604962317 0.9863310469415982 0.9863310469415982\n",
      "228 3 0.9702827987899402 0.9731423927276012 0.9731423927276012\n",
      "229 2 0.9759761769331146 0.9723625656640011 0.9759761769331146\n",
      "230 2 0.970310650887574 0.9629437869822486 0.970310650887574\n",
      "231 3 0.9789233858510966 0.9798424467099167 0.9798424467099167\n",
      "232 3 0.9767324343077805 0.9824116812984585 0.9824116812984585\n",
      "233 2 0.9662186800020837 0.9613654911357679 0.9662186800020837\n",
      "234 2 0.9499225776694231 0.9465703554838072 0.9499225776694231\n",
      "235 2 0.963782711528191 0.9626993209735256 0.963782711528191\n",
      "236 2 0.9792420711653198 0.966532797858099 0.9792420711653198\n",
      "237 3 0.9763088622404213 0.9793799356536999 0.9793799356536999\n",
      "238 2 0.9876520165979872 0.9786638333309403 0.9876520165979872\n",
      "239 3 0.9751269585681551 0.9758623892983217 0.9758623892983217\n",
      "240 2 0.9738373917409314 0.9712407430651436 0.9738373917409314\n",
      "241 2 0.9765979634400688 0.9686464850938535 0.9765979634400688\n",
      "242 2 0.968393715843096 0.9678086785291307 0.968393715843096\n",
      "243 2 0.9671400315233181 0.9288407454337546 0.9671400315233181\n",
      "244 2 0.9632907104750614 0.9327970192226268 0.9632907104750614\n",
      "245 3 0.9747056514913659 0.9805141287284145 0.9805141287284145\n",
      "246 2 0.9807124400147657 0.979965770663445 0.9807124400147657\n",
      "247 3 0.9732526507774584 0.9833070574051748 0.9833070574051748\n",
      "248 2 0.9823739509257481 0.9642193606252802 0.9823739509257481\n",
      "249 3 0.9746801705756929 0.9795179944433676 0.9795179944433676\n",
      "250 2 0.974552717216721 0.9734842665400355 0.974552717216721\n",
      "251 3 0.9538739637224957 0.9546375366203329 0.9546375366203329\n",
      "252 3 0.9675810279148193 0.9738805970149255 0.9738805970149255\n",
      "253 2 0.9786324786324787 0.9715859776100741 0.9786324786324787\n",
      "254 2 0.9744182509505703 0.9713155893536121 0.9744182509505703\n",
      "255 2 0.9656998363825673 0.9642570281124498 0.9656998363825673\n",
      "256 2 0.9860156454569258 0.9785938727415555 0.9860156454569258\n",
      "257 3 0.9751115061665687 0.975500388882716 0.975500388882716\n",
      "258 3 0.9564345278341221 0.9598903162797686 0.9598903162797686\n",
      "259 2 0.9805991902834008 0.954834008097166 0.9805991902834008\n",
      "260 2 0.9741408666534239 0.9737861460313856 0.9741408666534239\n",
      "261 3 0.970555865575397 0.9740280877976191 0.9740280877976191\n",
      "262 2 0.9650730411686586 0.9524402390438247 0.9650730411686586\n",
      "263 2 0.9595829569406804 0.9365853658536585 0.9595829569406804\n",
      "264 2 0.9699012684921877 0.9595009106304115 0.9699012684921877\n",
      "265 2 0.9760336538461538 0.9698798076923077 0.9760336538461538\n",
      "266 2 0.9653240460327073 0.9535963052695335 0.9653240460327073\n",
      "267 2 0.9847731171058787 0.9694838609075315 0.9847731171058787\n",
      "268 3 0.9525476387738194 0.964098315382491 0.964098315382491\n",
      "269 2 0.9804505678644572 0.9704043319059144 0.9804505678644572\n",
      "270 2 0.9721396514542171 0.9637247187736785 0.9721396514542171\n",
      "271 2 0.9526219394640447 0.9413758755864019 0.9526219394640447\n",
      "272 3 0.9774907248212832 0.9864642717099509 0.9864642717099509\n",
      "273 2 0.9560201249132547 0.9511071856665194 0.9560201249132547\n",
      "274 2 0.9849006379365737 0.9827206388544678 0.9849006379365737\n",
      "275 2 0.9671501887432666 0.9510186481175156 0.9671501887432666\n",
      "276 2 0.9795081967213115 0.9625098300163331 0.9795081967213115\n",
      "277 3 0.9824380165289257 0.9852634738998376 0.9852634738998376\n",
      "278 3 0.9697838930348261 0.9728700248756219 0.9728700248756219\n",
      "279 3 0.9789514132012638 0.9795662197933567 0.9795662197933567\n",
      "280 2 0.9803684376976596 0.9605154965211891 0.9803684376976596\n",
      "281 3 0.9754344097248118 0.9770900141695877 0.9770900141695877\n",
      "282 2 0.9752187028657617 0.9709728506787332 0.9752187028657617\n",
      "283 2 0.9714686770550753 0.9681013816163018 0.9714686770550753\n",
      "284 2 0.9783574720210665 0.9305381830151415 0.9783574720210665\n",
      "285 3 0.98113731521832 0.9818849867555328 0.9818849867555328\n",
      "286 2 0.9850636065775509 0.9659585595840576 0.9850636065775509\n",
      "287 2 0.9550319390700815 0.9409741416374915 0.9550319390700815\n",
      "288 2 0.967577582213988 0.9640883124903504 0.967577582213988\n",
      "289 2 0.9785042942796953 0.9338275806190245 0.9785042942796953\n",
      "290 2 0.9740767931869907 0.9721019014756627 0.9740767931869907\n",
      "291 3 0.9752350496625306 0.9767602935541868 0.9767602935541868\n",
      "292 2 0.985577386886195 0.9830047914589832 0.985577386886195\n",
      "293 3 0.9617707916166065 0.96279702309438 0.96279702309438\n",
      "294 3 0.9771937965929164 0.978436274363043 0.978436274363043\n",
      "295 2 0.9721581983939398 0.9701542933482097 0.9721581983939398\n",
      "296 3 0.9704288696506416 0.9743660588199178 0.9743660588199178\n",
      "297 2 0.9693696498054474 0.9318132295719843 0.9693696498054474\n",
      "298 2 0.970053441084463 0.9630539624608969 0.970053441084463\n",
      "299 2 0.9796133257248445 0.9713187141653761 0.9796133257248445\n",
      "300 2 0.9730609461218922 0.9725571951143902 0.9730609461218922\n",
      "301 2 0.991661013116237 0.9906009724106739 0.991661013116237\n",
      "302 3 0.9692951100943666 0.9737775235916499 0.9737775235916499\n",
      "303 3 0.9740912973332068 0.9792398215810951 0.9792398215810951\n",
      "304 2 0.9790262883173579 0.975435766030812 0.9790262883173579\n",
      "305 2 0.9799348988607302 0.9691932108811905 0.9799348988607302\n",
      "306 2 0.9807882360959651 0.9724475190839694 0.9807882360959651\n",
      "307 2 0.9724132730015083 0.9593589743589743 0.9724132730015083\n",
      "308 2 0.9770964941169427 0.9660638903026855 0.9770964941169427\n",
      "309 2 0.9791344426216702 0.9727052574017654 0.9791344426216702\n",
      "310 3 0.9667817280496336 0.9673139503056476 0.9673139503056476\n",
      "311 3 0.9723920545637347 0.979484253145295 0.979484253145295\n",
      "312 3 0.9579003035040927 0.9662926515221191 0.9662926515221191\n",
      "313 2 0.9666640196934807 0.9504327801159375 0.9666640196934807\n",
      "314 3 0.9697842036497295 0.9713850880845382 0.9713850880845382\n",
      "315 2 0.9675991960580913 0.9655731327800829 0.9675991960580913\n",
      "316 3 0.9675832036347057 0.9757188448175571 0.9757188448175571\n",
      "317 3 0.9755071851225698 0.9781628627782475 0.9781628627782475\n",
      "318 2 0.9748996599160515 0.9734520052697693 0.9748996599160515\n",
      "319 2 0.9768539711604487 0.9679918173495079 0.9768539711604487\n",
      "320 3 0.9612227780606897 0.9660980139592009 0.9660980139592009\n",
      "321 3 0.9614466382759066 0.9645760743321719 0.9645760743321719\n",
      "322 2 0.9743696033037167 0.9623560880991116 0.9743696033037167\n",
      "323 2 0.9795469912102771 0.9788064651147815 0.9795469912102771\n",
      "324 3 0.9708499765037594 0.9776638862781956 0.9776638862781956\n",
      "325 3 0.981115668580804 0.9876866283839212 0.9876866283839212\n",
      "326 2 0.9752465483234715 0.9723161453930685 0.9752465483234715\n",
      "327 2 0.9742610298712661 0.9684414448193976 0.9742610298712661\n",
      "328 3 0.9675993217054264 0.975570796996124 0.975570796996124\n",
      "329 3 0.9612067510548523 0.9650886075949368 0.9650886075949368\n",
      "330 2 0.9835972563299178 0.9806080108391905 0.9835972563299178\n",
      "331 2 0.9717000835421888 0.9636752136752137 0.9717000835421888\n",
      "332 2 0.9625468164794008 0.9520880519903481 0.9625468164794008\n",
      "333 3 0.9717610599879835 0.9746940517977422 0.9746940517977422\n",
      "334 3 0.9803779926878169 0.9820512442505014 0.9820512442505014\n",
      "335 2 0.9704470142692905 0.9557313856766079 0.9704470142692905\n",
      "336 2 0.9731585981585982 0.9730991980991981 0.9731585981585982\n",
      "337 2 0.98290020614376 0.960182149978034 0.98290020614376\n",
      "338 2 0.9770604395604395 0.9616071428571429 0.9770604395604395\n",
      "339 3 0.9777488751406074 0.9814398200224973 0.9814398200224973\n",
      "340 2 0.9714221693641518 0.9660530534153782 0.9714221693641518\n",
      "341 3 0.9706547413296462 0.9708995852056688 0.9708995852056688\n",
      "342 2 0.974855352350815 0.9656956272201281 0.974855352350815\n",
      "343 3 0.969199358088247 0.9707008595897485 0.9707008595897485\n",
      "344 2 0.9663069384613107 0.9541087474648784 0.9663069384613107\n",
      "345 2 0.9664389317729083 0.9432037475099602 0.9664389317729083\n",
      "346 3 0.9558005842993123 0.9591226086137028 0.9591226086137028\n",
      "347 3 0.982521043644969 0.9905865260761466 0.9905865260761466\n",
      "348 3 0.9475157722624133 0.9778339940458747 0.9778339940458747\n",
      "349 2 0.9632184944684945 0.9581679894179895 0.9632184944684945\n",
      "350 3 0.9919919343223391 0.9951461904076049 0.9951461904076049\n",
      "351 2 0.974693597983066 0.9671592416094668 0.974693597983066\n",
      "352 3 0.9775760770148977 0.9827925651479684 0.9827925651479684\n",
      "353 2 0.9922796668979874 0.9881881795049734 0.9922796668979874\n",
      "354 2 0.9723909198113208 0.9709905660377358 0.9723909198113208\n",
      "355 3 0.9640373577758822 0.9681504720322689 0.9681504720322689\n",
      "356 3 0.9575665399239544 0.9642585551330798 0.9642585551330798\n",
      "357 2 0.9732540207094074 0.9732319894249835 0.9732540207094074\n",
      "358 2 0.9797720797720798 0.9404258509521667 0.9797720797720798\n",
      "359 2 0.9736089776412358 0.9651604369346305 0.9736089776412358\n",
      "360 2 0.974940845650012 0.9733891155996022 0.974940845650012\n",
      "361 3 0.981273248715109 0.9876409120595169 0.9876409120595169\n",
      "362 3 0.9661765643936977 0.970506155514448 0.970506155514448\n",
      "363 2 0.9706613988879133 0.9338088966930056 0.9706613988879133\n",
      "364 3 0.9688872739018088 0.9729570413436692 0.9729570413436692\n",
      "365 3 0.9761615229788663 0.9762943083976293 0.9762943083976293\n",
      "366 2 0.9800539083557952 0.9717548588452263 0.9800539083557952\n",
      "367 3 0.977985100605723 0.9789946390029938 0.9789946390029938\n",
      "368 3 0.9664743083003953 0.9674229249011859 0.9674229249011859\n",
      "369 3 0.9705605988214683 0.9733317407230451 0.9733317407230451\n",
      "370 3 0.9820909764156318 0.9829241198587216 0.9829241198587216\n",
      "371 3 0.9680923076923076 0.9773538461538462 0.9773538461538462\n",
      "372 3 0.9645459803354541 0.9653970090060316 0.9653970090060316\n",
      "373 2 0.9672043745727956 0.9484825700615174 0.9672043745727956\n",
      "374 3 0.9640937500000001 0.9665625 0.9665625\n",
      "375 3 0.9594862335177972 0.9615358338457334 0.9615358338457334\n",
      "376 2 0.9740720440912275 0.9736229103864072 0.9740720440912275\n",
      "377 3 0.9653861755029072 0.9695100881871309 0.9695100881871309\n",
      "378 2 0.9746811702925731 0.9427200550137534 0.9746811702925731\n",
      "379 3 0.9875938697318007 0.9882528735632184 0.9882528735632184\n",
      "380 2 0.9619916803600244 0.9587570872377909 0.9619916803600244\n",
      "381 2 0.9623185871655884 0.959703036661421 0.9623185871655884\n",
      "382 3 0.9811567709856683 0.9878619479379936 0.9878619479379936\n",
      "383 3 0.9654661016949153 0.9728813559322034 0.9728813559322034\n",
      "384 3 0.9625142552466712 0.9644618551815045 0.9644618551815045\n",
      "385 2 0.9650047483380816 0.9546850269072491 0.9650047483380816\n",
      "386 3 0.9651791699677006 0.966169480163325 0.966169480163325\n",
      "387 3 0.9707567735907817 0.9725708502024291 0.9725708502024291\n",
      "388 2 0.954780068416432 0.9512154512154514 0.954780068416432\n",
      "389 2 0.9722264559941743 0.9720401700282816 0.9722264559941743\n",
      "390 2 0.9808378175447379 0.9790389187836315 0.9808378175447379\n",
      "391 2 0.9901487294879534 0.9835080401734262 0.9901487294879534\n",
      "392 2 0.9738749858131881 0.9717611508341846 0.9738749858131881\n",
      "393 2 0.9776657285803627 0.9735537836147592 0.9776657285803627\n",
      "394 3 0.9647595546009841 0.9723072704839373 0.9723072704839373\n",
      "395 3 0.9701536368975857 0.9786933135491052 0.9786933135491052\n",
      "396 3 0.9709609747686648 0.9744525547445255 0.9744525547445255\n",
      "397 2 0.9798330527497193 0.9738987093153759 0.9798330527497193\n",
      "398 2 0.9746541030534351 0.9713889551526718 0.9746541030534351\n",
      "399 2 0.9669320913461539 0.9459435096153845 0.9669320913461539\n",
      "400 2 0.9785342157138833 0.9701140523796115 0.9785342157138833\n",
      "401 2 0.9822751234485521 0.9668273722140666 0.9822751234485521\n",
      "402 3 0.9711812308974714 0.9738469019171991 0.9738469019171991\n",
      "403 3 0.9687780974644848 0.9748471497932027 0.9748471497932027\n",
      "404 2 0.9711003003378804 0.9694421849580778 0.9711003003378804\n",
      "405 2 0.9777558082056352 0.9635360026363486 0.9777558082056352\n",
      "406 2 0.980596478620194 0.9706823898343839 0.980596478620194\n",
      "407 3 0.9796147961479615 0.980889808898089 0.980889808898089\n",
      "408 2 0.9697238566669779 0.9624622521092121 0.9697238566669779\n",
      "409 3 0.9809885931558935 0.9840707454775897 0.9840707454775897\n",
      "410 3 0.9688667133520075 0.9754901960784315 0.9754901960784315\n",
      "411 3 0.9675943802536611 0.9692725814595895 0.9692725814595895\n",
      "412 2 0.9583106591388342 0.9523331746139718 0.9583106591388342\n",
      "413 3 0.9745604190048633 0.9759072203516648 0.9759072203516648\n",
      "414 2 0.9875972762645915 0.9706288439814235 0.9875972762645915\n",
      "415 3 0.9662800088099258 0.9675501064532709 0.9675501064532709\n",
      "416 3 0.952976730594731 0.9783839067378233 0.9783839067378233\n",
      "417 2 0.980308029175482 0.9749226968087468 0.980308029175482\n",
      "418 2 0.9742723416703232 0.9625274243089075 0.9742723416703232\n",
      "419 2 0.9722074754286534 0.9709950498601048 0.9722074754286534\n",
      "420 3 0.9691112231182796 0.9737567204301076 0.9737567204301076\n",
      "421 2 0.9658817689670683 0.9520374765383841 0.9658817689670683\n",
      "422 2 0.9644432773109244 0.9574929971988794 0.9644432773109244\n",
      "423 2 0.9838969150211343 0.98243013059113 0.9838969150211343\n",
      "424 2 0.977880148043153 0.9764942121426884 0.977880148043153\n",
      "425 2 0.9671933412148128 0.9580391091797936 0.9671933412148128\n",
      "426 2 0.9703786480095876 0.9682894438506138 0.9703786480095876\n",
      "427 2 0.9620970549328133 0.9601893754786605 0.9620970549328133\n",
      "428 3 0.9407791514999373 0.9725586795531567 0.9725586795531567\n",
      "429 3 0.984360750113999 0.9857501139990881 0.9857501139990881\n",
      "430 2 0.9824050709877481 0.9713312862919162 0.9824050709877481\n",
      "431 3 0.9722327420356597 0.9764364594852528 0.9764364594852528\n",
      "432 2 0.9688000000000001 0.9349833333333333 0.9688000000000001\n",
      "433 3 0.9699957382638345 0.9771915158667714 0.9771915158667714\n",
      "434 3 0.9814768373389062 0.9836920933472659 0.9836920933472659\n",
      "435 2 0.9716835171568627 0.9615119485294117 0.9716835171568627\n",
      "436 2 0.9589933611239772 0.9566234367762854 0.9589933611239772\n",
      "437 3 0.968779449764402 0.9745554035567716 0.9745554035567716\n",
      "438 2 0.9728453617057642 0.9698044410260792 0.9728453617057642\n",
      "439 3 0.977669286338017 0.9795506866714296 0.9795506866714296\n",
      "440 2 0.9718910336513724 0.9657752752826332 0.9718910336513724\n",
      "441 2 0.9886500878348703 0.9885746047430829 0.9886500878348703\n",
      "442 2 0.9734745786399084 0.9669270760544483 0.9734745786399084\n",
      "443 3 0.9650920129007778 0.9703724783406058 0.9703724783406058\n",
      "444 2 0.9929118348776564 0.9907063197026023 0.9929118348776564\n",
      "445 3 0.9626986205692334 0.9738664804144113 0.9738664804144113\n",
      "446 2 0.9715727254914766 0.9645842858075893 0.9715727254914766\n",
      "447 3 0.9727355885691055 0.974209340538343 0.974209340538343\n",
      "448 2 0.9864364364364364 0.9843843843843844 0.9864364364364364\n",
      "449 2 0.9664496332884298 0.941655440802275 0.9664496332884298\n",
      "450 2 0.9705955790555922 0.9667768230887861 0.9705955790555922\n",
      "451 2 0.9726238913444369 0.9595176067675557 0.9726238913444369\n",
      "452 2 0.9843960886930174 0.9806844787219392 0.9843960886930174\n",
      "453 2 0.9744108527131783 0.9423100775193797 0.9744108527131783\n",
      "454 2 0.9705089908041937 0.9647030398875418 0.9705089908041937\n",
      "455 2 0.984291978746559 0.9750976249919978 0.984291978746559\n",
      "456 2 0.9791152416356877 0.9760223048327136 0.9791152416356877\n",
      "457 2 0.9683794466403163 0.9442487811630088 0.9683794466403163\n",
      "458 3 0.9618554095045501 0.9650488709133805 0.9650488709133805\n",
      "459 3 0.9770367346938775 0.9820081632653062 0.9820081632653062\n",
      "460 3 0.975470211854452 0.9828913364934151 0.9828913364934151\n",
      "461 2 0.9800973828362751 0.978119293974437 0.9800973828362751\n",
      "462 2 0.9667079478400233 0.9577256501784803 0.9667079478400233\n",
      "463 2 0.9850663011602704 0.983201581027668 0.9850663011602704\n",
      "464 3 0.9812636372260697 0.9828684818012206 0.9828684818012206\n",
      "465 2 0.9554800224076065 0.9283486502445154 0.9554800224076065\n",
      "466 2 0.9716087178365771 0.9661855820395074 0.9716087178365771\n",
      "467 2 0.9688177355603723 0.9648651663904119 0.9688177355603723\n",
      "468 2 0.9788210762192278 0.9528492732874794 0.9788210762192278\n",
      "469 3 0.961153624487705 0.9711193647540983 0.9711193647540983\n",
      "470 2 0.9828271359636673 0.9716505818904344 0.9828271359636673\n",
      "471 2 0.9626702334630348 0.9590223735408561 0.9626702334630348\n",
      "472 2 0.9843277469758064 0.962733114919355 0.9843277469758064\n",
      "473 2 0.9809414301113906 0.9751203736974488 0.9809414301113906\n",
      "474 2 0.9734600749152744 0.9599931624947975 0.9734600749152744\n",
      "475 2 0.9860168700199201 0.9855110806772908 0.9860168700199201\n",
      "476 2 0.995232749588385 0.9946265529112408 0.995232749588385\n",
      "477 2 0.9774154974489797 0.9683274872448979 0.9774154974489797\n",
      "478 2 0.9687383235770333 0.9572642919417114 0.9687383235770333\n",
      "479 3 0.9691483973663266 0.9706244121264742 0.9706244121264742\n",
      "480 2 0.9708916505791506 0.9588863416988417 0.9708916505791506\n",
      "481 3 0.9770708467803904 0.9789380666974028 0.9789380666974028\n",
      "482 3 0.9774570543508871 0.9786891016615037 0.9786891016615037\n",
      "483 3 0.9771953124999999 0.9796093749999999 0.9796093749999999\n",
      "484 2 0.9912513842746402 0.9855086220534726 0.9912513842746402\n",
      "485 2 0.9802499173950918 0.970615181280226 0.9802499173950918\n",
      "486 3 0.9656595940959409 0.9677583025830259 0.9677583025830259\n",
      "487 2 0.9711332355595669 0.944438176895307 0.9711332355595669\n",
      "488 2 0.9863182890291324 0.9800870147255689 0.9863182890291324\n",
      "489 3 0.9487994487994489 0.9743964743964745 0.9743964743964745\n",
      "490 3 0.9686276538866181 0.9700246632517548 0.9700246632517548\n",
      "491 2 0.9587868480725623 0.9477486232588274 0.9587868480725623\n",
      "492 2 0.9791914219430771 0.9752942341424773 0.9791914219430771\n",
      "493 2 0.9768002547423009 0.9496808139623043 0.9768002547423009\n",
      "494 2 0.9742845028619885 0.9592466963465479 0.9742845028619885\n",
      "495 3 0.9538198983297024 0.9564996368917937 0.9564996368917937\n",
      "496 2 0.9763901592075279 0.9706931030740849 0.9763901592075279\n",
      "497 3 0.9582827318991443 0.9755089058524173 0.9755089058524173\n",
      "498 3 0.9635407420557429 0.9678753180661578 0.9678753180661578\n",
      "499 3 0.9675950380152061 0.9704121648659464 0.9704121648659464\n",
      "500 2 0.973814229249012 0.9681085043988271 0.973814229249012\n",
      "501 2 0.9741669620701878 0.9717210209145694 0.9741669620701878\n",
      "502 3 0.9715859415981815 0.9780701754385965 0.9780701754385965\n",
      "503 2 0.9801377118644068 0.9740209814106069 0.9801377118644068\n",
      "504 3 0.9793249607535324 0.9841444270015699 0.9841444270015699\n",
      "505 2 0.980782574591969 0.9797870093824479 0.980782574591969\n",
      "506 2 0.9758877530905916 0.9675382275914506 0.9758877530905916\n",
      "507 2 0.9677940126175456 0.9655100583263898 0.9677940126175456\n",
      "508 2 0.9498539363779157 0.944745379545221 0.9498539363779157\n",
      "509 2 0.9667463733460864 0.9485094850948511 0.9667463733460864\n",
      "510 2 0.959849719355423 0.9484353310398939 0.959849719355423\n",
      "511 3 0.9709540602363707 0.9785550895920703 0.9785550895920703\n",
      "\n",
      "AUC: 0.97436\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "oof_gmm = np.zeros(len(train))\n",
    "oof_gmm_2 = np.zeros(len(train))\n",
    "oof_gmm_3 = np.zeros(len(train))\n",
    "preds_gmm = np.zeros(len(test))\n",
    "records_gmm = []\n",
    "\n",
    "# 512 models\n",
    "for i in tqdm_notebook(range(512)):\n",
    "\n",
    "    train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "    idx1 = train2.index\n",
    "    idx2 = test2.index\n",
    "    train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "                     ('scaler', StandardScaler())])\n",
    "    data2 = pipe.fit_transform(data[cols])\n",
    "    train3 = data2[:train2.shape[0]]\n",
    "    test3 = data2[train2.shape[0]:]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=15, random_state=42,shuffle=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        #######################################################################################\n",
    "        cluster_per_class = 2\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "        \n",
    "        gmm_2 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm_2.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob_2 = gmm_2.predict_proba(train3[test_index,:])\n",
    "        prob_class_2 = np.zeros(prob_2.shape[0])\n",
    "\n",
    "        for j in range(prob_2.shape[0]):\n",
    "            if(np.argmax(prob_2,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class_2[j] = np.max(prob_2,axis=1)[j]\n",
    "            else:\n",
    "                prob_class_2[j] = 1 - np.max(prob_2,axis=1)[j]\n",
    "                \n",
    "        #######################################################################################\n",
    "        cluster_per_class = 3\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values,cluster_per_class)\n",
    "        \n",
    "        gmm_3 = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm_3.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob_3 = gmm_3.predict_proba(train3[test_index,:])\n",
    "        prob_class_3 = np.zeros(prob_3.shape[0])\n",
    "\n",
    "        for j in range(prob_3.shape[0]):\n",
    "            if(np.argmax(prob_3,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class_3[j] = np.max(prob_3,axis=1)[j]\n",
    "            else:\n",
    "                prob_class_3[j] = 1 - np.max(prob_3,axis=1)[j]\n",
    "        \n",
    "        #######################################################################################\n",
    "        oof_gmm_2[idx1[test_index]] = prob_class_2\n",
    "        oof_gmm_3[idx1[test_index]] = prob_class_3\n",
    "        \n",
    "    gmm_2_score = roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1])\n",
    "    gmm_3_score = roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1])\n",
    "    gmm_score = [gmm_2_score,gmm_3_score]\n",
    "    \n",
    "    if(np.argmax(gmm_score) == 0):\n",
    "        cluster_per_class = 2\n",
    "    else:\n",
    "        cluster_per_class = 3\n",
    "\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values, cluster_per_class)\n",
    "        gmm = GaussianMixture(n_components=cluster_per_class * 2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "        \n",
    "        prob = gmm.predict_proba(train3[test_index,:])\n",
    "        prob_class = np.zeros(prob.shape[0])\n",
    "\n",
    "        for j in range(prob.shape[0]):\n",
    "            if(np.argmax(prob,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_class[j] = np.max(prob,axis=1)[j]\n",
    "            else:\n",
    "                prob_class[j] = 1 - np.max(prob,axis=1)[j]\n",
    "\n",
    "        oof_gmm[idx1[test_index]] = prob_class\n",
    "        \n",
    "        prob_test = gmm.predict_proba(test3)\n",
    "        prob_test_class = np.zeros(prob_test.shape[0])\n",
    "        for j in range(prob_test.shape[0]):\n",
    "            if(np.argmax(prob_test,axis=1)[j] in np.arange(cluster_per_class)):\n",
    "                prob_test_class[j] = np.max(prob_test,axis=1)[j]\n",
    "            else:\n",
    "                prob_test_class[j] = 1 - np.max(prob_test,axis=1)[j]\n",
    "\n",
    "        preds_gmm[idx2] += prob_test_class / skf.n_splits\n",
    "        \n",
    "    print(i, cluster_per_class, roc_auc_score(train['target'][idx1].values, oof_gmm_2[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm_3[idx1]),roc_auc_score(train['target'][idx1].values, oof_gmm[idx1]))\n",
    "    records_gmm.append(roc_auc_score(train['target'][idx1].values, oof_gmm[idx1]))\n",
    "        \n",
    "auc = roc_auc_score(train['target'], oof_gmm)\n",
    "print(f'AUC: {auc:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = preds_gmm\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for itr in range(1):\n",
    "#     test['target'] = preds_gmm\n",
    "#     test.loc[test['target'] > 0.95, 'target'] = 1\n",
    "#     test.loc[test['target'] < 0.05, 'target'] = 0\n",
    "#     usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n",
    "#     new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n",
    "#     print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n",
    "    \n",
    "#     new_train.loc[oof_gmm > 0.98, 'target'] = 1\n",
    "#     new_train.loc[oof_gmm < 0.02, 'target'] = 0\n",
    "    \n",
    "#     oof_gmm2 = np.zeros(len(train))\n",
    "#     preds_gmm = np.zeros(len(test))\n",
    "    \n",
    "#     for i in tqdm_notebook(range(512)):\n",
    "\n",
    "#         train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "#         test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "#         idx1 = train2.index\n",
    "#         idx2 = test2.index\n",
    "#         train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#         data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "#         pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "#                          ('scaler', StandardScaler())])\n",
    "#         data2 = pipe.fit_transform(data[cols])\n",
    "#         train3 = data2[:train2.shape[0]]\n",
    "#         test3 = data2[train2.shape[0]:]\n",
    "\n",
    "#         skf = StratifiedKFold(n_splits=11, random_state=2019,shuffle=True)\n",
    "\n",
    "#         for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "#             # MODEL AND PREDICT WITH QDA\n",
    "#             ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "\n",
    "#             gmm = GaussianMixture(n_components=component_num*2, init_params='kmeans', covariance_type='full', max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "#             gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "\n",
    "#             prob = gmm.predict_proba(train3[test_index,:])\n",
    "#             prob_class = np.zeros(prob.shape[0])\n",
    "\n",
    "#             for j in range(prob.shape[0]):\n",
    "#                 if(np.argmax(prob,axis=1)[j] in {0, 1}):\n",
    "#                     prob_class[j] = np.max(prob,axis=1)[j]\n",
    "#                 else:\n",
    "#                     prob_class[j] = 1 - np.max(prob,axis=1)[j]\n",
    "\n",
    "#             oof_gmm2[idx1[test_index]] = prob_class\n",
    "\n",
    "# #             prob_test = gmm.predict_proba(test3)\n",
    "# #             prob_test_class = np.zeros(prob_test.shape[0])\n",
    "# #             for j in range(prob_test.shape[0]):\n",
    "# #                 if(np.argmax(prob_test,axis=1)[j] in {0, 1, 2}):\n",
    "# #                     prob_test_class[j] = np.max(prob_test,axis=1)[j]\n",
    "# #                 else:\n",
    "# #                     prob_test_class[j] = 1 - np.max(prob_test,axis=1)[j]\n",
    "\n",
    "# #             preds_gmm[idx2] += prob_test_class / skf.n_splits\n",
    "    \n",
    "#     auc = roc_auc_score(train['target'], oof_gmm2)\n",
    "#     print(f'AUC: {auc:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# train2 = train[train['wheezy-copper-turtle-magic'] == i]\n",
    "# test2 = test[test['wheezy-copper-turtle-magic'] == i]\n",
    "# idx1 = train2.index\n",
    "# idx2 = test2.index\n",
    "# train2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "# pipe = Pipeline([('vt', VarianceThreshold(threshold=2)),\n",
    "#                  ('scaler', StandardScaler())])\n",
    "# data2 = pipe.fit_transform(data[cols])\n",
    "# train3 = data2[:train2.shape[0]]\n",
    "# test3 = data2[train2.shape[0]:]\n",
    "\n",
    "# print(train2.shape)\n",
    "# print(train3.shape)\n",
    "# print(train2['target'].shape)\n",
    "\n",
    "# np.random.seed(42)\n",
    "# for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "#     # MODEL AND PREDICT WITH QDA\n",
    "#     ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "\n",
    "#     gmm = GaussianMixture(n_components=6, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=200, n_init=1,means_init=ms, precisions_init=ps)\n",
    "#     gmm.fit(np.concatenate([train3,test3],axis = 0))\n",
    "#     prob = gmm.predict_proba(train3[test_index,:])\n",
    "#     prob_class = np.zeros(prob.shape[0])\n",
    "    \n",
    "#     for j in range(prob.shape[0]):\n",
    "#         if(np.argmax(prob,axis=1)[j] in {0,1,2}):\n",
    "#             prob_class[j] = np.max(prob,axis=1)[j]\n",
    "#         else:\n",
    "#             prob_class[j] = 1 - np.max(prob,axis=1)[j]\n",
    "    \n",
    "#     oof_gmm[idx1[test_index]] = prob_class\n",
    "# #     preds_gmm[idx2] += gmm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "# print(roc_auc_score(train['target'][idx1].values, oof_gmm[idx1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
